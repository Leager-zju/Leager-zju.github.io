---
title: 6.824 Lab4 Sharded Key/Value Service
author: Leager
mathjax: true
date: 2022-11-22 20:20:28
summary:
categories:
    - MIT6.824
tags:
    - lab
img:
---

对于单个副本组而言，所有机器存储共享同一存储空间，机器数量的增加并不会扩大存储能力。而当 kv 对数量不断增长时，副本组的存储能力成为瓶颈。

参考 [Aurora](https://leager-zju.github.io/6-824/aurora/) 的做法，不妨将数据划分为多个片段，每个副本组负责**分片**(Shard)的一个子集。组内机器使用 Raft 来复制分片。此外还有一个**分片控制器**(Shardctrler)，决定哪个副本组应该为每个分片服务，此信息称为**配置**(Config)。本实验就是实现这样一个 multi-raft 的 kv 存储系统。

<!--more-->

lab4 和 lab3 非常像，主要流程是这样的：

1. client 通过 clerk 发送请求；
2. clerk 根据 key 所在的分片，将请求转发给对应 group 的 Leader；
3. Leader 通过 raft 层复制操作日志。

## PART A-The Shard controller

这一部分是比较简单的，去重检测、处理请求等方面几乎可以把 lab3 的代码搬过来。关键在于处理上层调用的 `Join`、`Leave`、`Move`、`Query` 这 4 个命令。由于 Shardctrler 管理一系列配置，故需要在结构体中额外设置一个 Config 切片。结构体如下：

```go
type ShardCtrler struct {
    mu      sync.RWMutex
    me      int
    applyCh chan raft.ApplyMsg
    rf      *raft.Raft

    lastRequestInfo map[int64]*RequestInfo // clerkID -> requestID
    configs []Config // indexed by config num
}
```

### 新建配置

`Query` 相当于读命令，不会对 Config 有任何更改，是可以不经过去重的，直接根据规则返回相应 Config 即可。

其它 3 个需要经过去重表。其中 `Move` 较为简单，直接修改 Config 中 `Shards[]` 对应的值即可。对于 `Join` 和 `Leave`，在应用命令时需要创建一个新的 Config。

> 在 Go 中，map 是引用类型，不能直接拷贝（浅拷贝），而是需要创建一个新的对象并单独复制键和值（深拷贝）。

```go
func (sc *ShardCtrler) makeNewConfig() *Config {
    lastconfig := sc.configs[len(sc.configs)-1]
    newconfig := Config{
        Num:    lastconfig.Num + 1,
        Shards: lastconfig.Shards,
        Groups: make(map[int][]string),
    }
    for gid, members := range lastconfig.Groups {
        newconfig.Groups[gid] = members
    }
    return &newconfig
}


func (sc *ShardCtrler) ApplyCommand(msg raft.ApplyMsg) {
    args := msg.Command.(Args)
    ch := args.Ch
    reply := new(Reply)

    if args.Op == Query {
        reply.Err = OK
        if args.Num == -1 || args.Num >= len(sc.configs) {
            reply.Config = sc.configs[len(sc.configs)-1]
        } else {
            reply.Config = sc.configs[args.Num]
        }
    } else if sc.isDuplicated(args.RequestId, args.ClerkId) {
        reply.Err = sc.lastRequestInfo[args.ClerkId].Err
    } else {
        newconfig := sc.makeNewConfig()
        switch args.Op {
            case Move:
            newconfig.Shards[args.Shard] = args.GIDs[0]
            case Join:
            for gid, members := range args.Servers {
                newconfig.Groups[gid] = members
            }
            sc.shuffleShard(newconfig)
            case Leave:
            for _, gid := range args.GIDs {
                delete(newconfig.Groups, gid)
            }
            sc.shuffleShard(newconfig)
        }
        DPrintf("[ShardCtrler]: NewConfig %+v", newconfig)
        sc.configs = append(sc.configs, *newconfig)
        sc.lastRequestInfo[args.ClerkId] = &RequestInfo{
            RequestID: args.RequestId,
            Err:       reply.Err,
        }
    }

    if sc.rf.GetRaftState() == raft.Leader && sc.rf.GetCurrentTerm() == msg.CommandTerm {
        go func(reply_ *Reply) { ch <- reply_ }(reply)
    }
}
```

### 分片再分配

lab 要求**新 Config 应尽可能将 Shard 均匀地分配到 groups 中，并应移动尽可能少的 Shard**。这样做也是为了减少不必要的网络资源消耗，毕竟后续 Shard 的迁移是需要 rpc 的。

若分配前存在分片处于**无主**状态（即 Config.Shards[i] = 0），则优先**将该分片分配给拥有最少分片的 group**。反之，则**每次选取拥有最多分片的 group 给拥有最少分片的 group 迁移 Shard，直至两者拥有数量不超过 1**。

> 在 Go 中，map 迭代顺序是[不确定的](https://blog.golang.org/maps#TOC_7.)。

```go
func (sc *ShardCtrler) shuffleShard(config *Config) {
    N := len(config.Groups)
    if N == 0 {        // 所有 group 离开，将所有 Shard 设为无主
        for i := 0; i < NShards; i++ {
            config.Shards[i] = 0
        }
        return
    }

    allocated := 0
    NumofShards := make(map[int]int)
    for gid := range config.Groups {
        NumofShards[gid] = 0
    }
    for _, gid := range config.Shards {
        if _, ok := config.Groups[gid]; ok {
            allocated++
            NumofShards[gid]++
        }
    }

    for {
        WhoHasTheMostShards, WhoHasTheLeastShards := -1, -1
        MaxmShards, MinmShards := -1, NShards+1

        for gid, num := range NumofShards {
            if num > MaxmShards {
                MaxmShards = num
                WhoHasTheMostShards = gid
            }
            if num < MinmShards {
                MinmShards = num
                WhoHasTheLeastShards = gid
            }
        }
        if allocated == NShards && MaxmShards < MinmShards+2 {    // allocated != NShards 说明存在无主分片，不能简单凭 MaxmShards < MinmShards+2 退出循环
            break
        }

        for sid, gid := range config.Shards {
            if _, ok := config.Groups[gid]; !ok { // gid 已离开，直接分给拥有分片最少的 group
                config.Shards[sid] = WhoHasTheLeastShards
                allocated++
                NumofShards[WhoHasTheLeastShards]++
                break
            } else if gid == WhoHasTheMostShards && allocated == NShards {
                config.Shards[sid] = WhoHasTheLeastShards
                NumofShards[WhoHasTheMostShards]--
                NumofShards[WhoHasTheLeastShards]++
                break
            }
        }
    }
}
```

## PART B-Shared Key/Value Server

这一部分我认为是整个 6.824 lab 中最难的一个 Part。尽管 raft 算法也很难，但只要认真研读论文的图 2，依然能够写出 bugfree 的代码。这部分的难点在于，需要我们从头设计一个基于 Shard 的 KV 服务，而没有任何文献资料/Guide 来作指引，一旦没有灵感迸发，就会寸步难行。

### 开始 4B 之前需要想明白的一些事

磨蹭大半个月+仔细阅读实验要求后，我得出如下总结：

该部分与 lab3 的不同之处在于，group 会不断加入/离开系统，为了平衡负载，系统需要在 group 之间转移 Shard。同时，随着 groups 的变化，系统的 Config 也会不断发生变化，且需要告知所有 group。简而言之，该 lab 的难点并不在于对 client 操作的实现——它已经在 lab3 中做完了，直接照抄即可——而是

1. **如何 ReConfig，Config 有更新后怎么做**；
2. **如何迁移 Shard，迁移后怎么做**。

能够想明白上面两个问题，4B 的所有难点都迎刃而解，包括两个 Challenge。

### Clerk

clerk 的工作和 lab3 非常相似，样例代码的思路也很清楚——一旦收到 ErrWrongGroup 回复，则说明自己缓存的 Config 有误，需向 Shardctrler 请求最新的 Config。和 lab3 类似，Clerk 需要缓存每个 group 的 Leader。

这里有个很重要的一点：如果对某个 group 所有成员均发送失败，则认为该 group 全挂了，系统发生成员变动，此时 clerk 缓存的 Config 一定已过时，再继续发下去极有可能死循环，需要尝试获取最新 Config。

```go
func (ck *Clerk) SendRequest(Command *OperationCommand) string {
    Command.ClerkId, Command.RequestId = ck.ClerkId, ck.RequestId

    for {
        shard := key2shard(Command.Key)
        gid := ck.config.Shards[shard]

        if servers, ok := ck.config.Groups[gid]; ok { // 若 gid 在当前 config 中
            if _, ok := ck.volatileLeader[gid]; !ok {
               ck.volatileLeader[gid] = 0
            }

            guard := ck.volatileLeader[gid]
            leader := guard

            for {
                reply := new(Reply)
                srv := ck.make_end(servers[leader])
                ok := srv.Call("ShardKV.HandleRequest", Command, reply)
                DPrintf("[client] %s %s, %s -> %d send to %s and get reply %+v", Command.Op, Command.Key, Command.Value, shard, servers[leader], reply)
                if ok && (reply.Err == OK || reply.Err == ErrNoKey) { // OK
                    ck.volatileLeader[gid] = leader
                    ck.RequestId++
                    return reply.Value
                } else if ok && reply.Err == ErrWrongGroup { // arrive but WrongGroup
                    break
                } else { // not arrive / arrive but WrongLeader
                    leader = (leader + 1) % len(ck.config.Groups[gid])
                    if leader == guard { // all members failed
                        break
                    }
                    continue
                }
            }
        }

        time.Sleep(100 * time.Millisecond)
        ck.config = ck.sm.Query(-1)
    }
}
```

### Server

首先思考第一个问题，**如何 ReConfig，Config 有更新后怎么做**。这个问题还是比较容易的，只需要在启动 server 时异步开启一个 **ConfigPuller** 协程，定期向 Shardctrler 请求最新的 Config 即可。每个 server 还需维护一个 CurrentConfig 变量，一旦获得较新的 Config，就将其赋给 CurrentConfig。

> 这个变量主要用于收到操作请求时判断是否返回 ErrWrongGroup，即如果 CurrentConfig.Shards[key2shard(key)] != kv.gid，说明本 group 不负责该分片，需报错。

这里有一个问题，group 里的每个成员能够单独进行 Config 的拉取和更新吗？回答显然是**不能**的，这是对 raft 层的不尊重，单独进行 Config 拉取必然会造成不同步，则后续对不同 server 存储的读写也会产生管辖范围不一致的问题。所以这里需要进行是否为 Leader 的判断，如果 Leader 拿到了较新的Config，则向下层发一条更新记录，随着 raft 层的运作，这条记录最终会被所有 server 获得，传到上层进行 Apply 后更新 CurrentConfig。

随着 Config 的更新，Shard 的迁移问题也随之而来，这里我设计为新 owner 向旧 owner 发送 **pull** 请求：旧 owner 收到 rpc 后将属于该 Shard 的 kv 对打包进 reply 中发回给新 owner。

> 当然 push 也是可以的。

最开始我将节点的存储简单的设计为了单个 map，后来发现这样做不够优雅——所有数据都存到同一块区域，每次迁移 Shard 时需要对所有元素进行遍历，尽管对 Config/Shard 的操作只需要对服务器上一把大锁，但 O(n) 的遍历无端增加了时间消耗，显然是现实不可用的。

在阅读了 Aurora 的论文后我有所启发：我们完全可以定义一个名为 Shard 的结构体，每个 Shard 拥有单独的 map 存储，这样一来进行分片迁移/垃圾回收时便能**以 Shard 为粒度**进行操作，而不需要遍历所有数据，还能对每个 Shard 进行一些额外的变量设置。

那么能不能在 Apply 更新 Config 日志后立马进行一次 pull Shard 呢？我最开始尝试通过条件变量来进行协程之间的通信，更新完 CurrentConfig 后通知另一个协程发送 pull Shard rpc。但考虑到一旦这个环节 group 挂了，server 重启后并不能够知道当前进行到哪一步，并且 Shard 在 pull 之前是不能提供服务的。所以这个方法立即被我弃用了。

不妨换个思路。任意时刻，server 可能会拥有以下几类 Shard：

1. 继续持有的；
2. 不再持有，等待被其它 server pull 的；
3. 不再持有，但已经被其它 server pull 的；
4. 新持有，等待 server 从其他 group 那 pull 的；
5. 新持有，已经 pull 到了的；

> 如果考虑要做 Challenge1，又能够把 3 和 5 进一步细分为：
>
> 1. 继续持有的；
> 2. 不再持有，等待被其它 server pull 的；
> 3. 不再持有，但
>     1. 被 pull，等待接受 GC 通知；
>     2. 被 pull，已进行 GC；
> 4. 新持有，等待 server 从其他 group 那 pull 的；
> 5. 新持有，且
>     1. pull 到，需发送 GC 通知；
>     2. pull 到，GC 发送完毕。
>
> 之所以设计为**新 owner pull 到 Shard 后向旧 owner 发送 GC 通知**而不是**旧 owner 在收到 pull Shard 并 reply OK 后自行 GC**，还是因为如果 reply 发过去的途中新 owner 挂了，重启后因为没 pull 到还得重新发 pull Shard 请求，而此时旧 owner GC 完毕后存储清空了，就会产生错误——系统永久性地失去了该 Shard 对应的数据。
>
> 收到 GC 通知也意味着新 owner 收到了 reply 并完成了 Shard 的覆盖，可以进行数据回收而不用担心是否挂掉。当然，新 owner 收到 reply 也意味着旧 owner 完成了 GC，不用再发送 GC 通知了。

我选择了完成 Challenge。为了对这些不同种类的 Shard 进行区分，最优雅的做法是在 Shard 结构体内设置一个 **ShardStatus** 变量，这样无论是否挂掉，group 都能在**任意时刻**根据 Shard 内部的 Status 变量进行相应的操作。那么其实思路很简单了，除了 ConfigPuller 协程，我们再启动两个 ShardPuller 和 GarbageCollector 协程，异步地进行**遍历 Shard 并根据 ShardStatus 执行 rpc 等操作**。和之前提到的一样，我们依然需要 Leader 来进行一系列交互行为，并利用 raft 层进行日志同步，所有 server 收到下层传上来的 ApplyMsg 后执行最终的修改操作。

> 其中 1, 3.b, 5.b 都意味着无需任何后续操作，统一设置为 Ready 状态

```go
type status int

const (
    // everyone
    Ready status = iota // 一切就绪
    // new owner
    NeedPull           // 表明该分片等待从其他 group 处拉取
    ReadyButNeedSendGC // 就绪，但需要通知其他 group 进行 GC
    // old owner
    Waiting // 表明该分片等待被其他 group 拉取 + 通知 GC
)

type Shard struct {
    KVs         map[string]string
    ShardStatus status
}
```

一个 Shard 能不能正确处理 client 请求，一是看它是否被当前 server 持有，二是看该 Shard 状态是否为 Ready/ReadyButNeedSendGC，任一条件不满足，都返回 `ErrWrongGroup`。在 Apply 客户端操作时，需要将 lab3 的代码修改为：

```go
func (kv *ShardKV) ApplyCommand(msg raft.ApplyMsg) {
    // locked
    command := msg.Command.(OperationCommand)
    ch := command.Ch
    reply := new(Reply)

    shardId := key2shard(command.Key)

    if !kv.ReadyForServer(shardId) {
        reply.Err = ErrWrongGroup
    } else if command.Op == "Get" {
        val, ok := kv.Shards[shardId].KVs[command.Key]
        if ok {
            reply.Value, reply.Err = val, OK
        } else {
            reply.Value, reply.Err = "", ErrNoKey
        }
    } else if kv.isDuplicated(command.RequestId, command.ClerkId) {
        reply.Err = kv.lastRequestInfo[command.ClerkId].Err
    } else {

        if command.Op == "Put" {
            kv.Shards[shardId].KVs[command.Key] = command.Value
            reply.Err = OK
        } else if command.Op == "Append" {
            _, ok := kv.Shards[shardId].KVs[command.Key]
            if ok {
                kv.Shards[shardId].KVs[command.Key] += command.Value
                reply.Err = OK
            } else {
                kv.Shards[shardId].KVs[command.Key] = command.Value
                reply.Err = ErrNoKey
            }
        } else {
            log.Fatalf("command.op error!")
        }

        DPrintf("[%d %d] %s (%s, %s) success and the value become %s", kv.gid, kv.me, command.Op, command.Key, command.Value, kv.Shards[shardId].KVs[command.Key])

        kv.lastRequestInfo[command.ClerkId] = &RequestInfo{
            RequestID: command.RequestId,
            Err:       reply.Err,
        }
    }

    DPrintf("[%d %d] Apply Command #%d %s (%s, %s) and reply %+v", kv.gid, kv.me, msg.CommandIndex, command.Op, command.Key, command.Value, reply)
    if kv.rf.GetRaftState() == raft.Leader && kv.rf.GetCurrentTerm() == msg.CommandTerm {
        go func(reply_ *Reply) {
            ch <- reply_
        }(reply)
    }
}
```

考虑到 group 会挂掉这个情况，重启后找谁 pull Shard 也是个问题，故除了 CurrentConfig，server 内部还需设置一个 LastConfig 变量。在 lab3 的基础上，server 结构体应该修改为这样：

```go
type ShardKV struct {
    mu       sync.RWMutex
    me       int
    mck      *shardctrler.Clerk
    rf       *raft.Raft
    applyCh  chan raft.ApplyMsg
    make_end func(string) *labrpc.ClientEnd
    gid      int
    ctrlers  []*labrpc.ClientEnd

    maxraftstate int // snapshot if log grows this big
    lastapplied  int

    Shards          [shardctrler.NShards]Shard
    lastRequestInfo map[int64]*RequestInfo

    lastConfig    shardctrler.Config
    currentConfig shardctrler.Config
}
```

这样一来整体的工作流程就很明朗了：

1. ConfigPuller 获得较新的 Config，通过 rf.Start 进行 `UpdateConfig` 日志同步；
2. Apply 到 `UpdateConfig` 日志后，对于仍持有的 Shard，不作变动；对于不再持有的，设置状态为 Waiting；对于新持有的，设置状态为 `NeedPull`；
3. Leader 的 ShardPuller 检测到存在状态为 `NeedPull` 的 Shard 后，根据 LastConfig 找到旧 owner 并发送 pull Shard rpc；
4. 旧 owner 打包 Shard 发回 reply；
5. 新 owner 收到 reply 后，立即 rf.Start 一个 `InsertShard` 日志，并在 Apply 后设置相应 Shard 的状态为 `ReadyButNeedSendGC`；
6. GarbageCollector 检测到存在状态为 `ReadyButNeedSendGC` 的 Shard 后，根据 LastConfig 找到旧 owner 并发送 garbage collector rpc；
7. 旧 owner 收到 GC 通知，立即 rf.Start 一个 `GarbageCollect` 日志，Apply 后清理数据，并设置状态为 `Ready`；
8. 新 owner 收到 GC 的 reply 后，也 rf.Start 一个 `GarbageCollect` 日志，Apply 后设置状态为 `Ready`。

> 7, 8 两步的不同之处在于，新旧 owner Apply GC 日志时，相应的 Shard 状态不同，前者为 `ReadyButNeedSendGC`，后者为 `Waiting`。根据状态不同执行不同操作即可，而不需要为新 owner 再新定义一个 `UpdateStatus` 这样的日志类别。

然而，ConfigPuller 也不能无条件进行 UpdateConfig，否则会破坏当前 Shard 的状态，甚至可能存在部分 Shard 仍未 pull 到就需要回复其它 group 的 pull 请求，结果是一部分任务永远无法正确完成，从而系统陷入无尽的错误。由于我们引入了 ShardStatus 这一概念，故令**仅当所有 Shard 都变为 Ready 后才能更新 Config** 是一种更安全的行为。

另外，可能某些 Shard 在迁移前仍然由旧 owner 向 client 提供服务，故存在这样一种情况：client 向 group1 发送 shard1 写请求后，group1 实际上执行了这一操作，但给 client 的 reply 丢包了，而其它 server 由于不是 Leader 无法应对请求，故认为 group1 全挂了，此时恰好发现 Config 存在更新，且新 Config 下 shard1 归属于 group2，client 转而向 group2 发送同一写请求。group2 向 group1 pull 了应用过请求的 Shard 后，收到 client 的同一请求，又执行了一遍。为了满足幂等性，pull Shard reply 里还应该包括旧 owner 的去重表来应对这一情况。新 owner 收到后会和自己的去重表进行比对，取同一 clerkId 下的最新 request。

另外，我也遇到了[谭佬遇到的同样问题](https://github.com/OneSizeFitsQuorum/MIT6.824-2021/blob/master/docs/lab4.md)：

> 最后，在 lab2 的文档中我就提到了 leader 上线后应该立刻 append 一条空日志，这样才可以保证 leader 的状态机最新，然而不幸的是，lab2 的测试在加了空日志后便 Fail 了，因此我便没有再关注。在实现 lab4 时，我最开始并没有关注这件事，最后成了一个大坑，导致我花费了一天的时间才找到问题。该 bug 一般跑 100 次测试能够复现一次，对外的表现是集群出现活锁，无法再服务请求直到超时，而且仅会在几个涉及到重启的测试中出现。经过一番探索，最终发现是在节点频繁的重启过后，出现了 lab2 中描述空日志必要性的例子。这导致某一 raft 组的状态机无法达到最新且不全是默认状态，这使得配置更新协程也无法提交新的配置日志，此时客户端碰巧没有向该 raft 组执行读写请求，因而该 raft 组始终没有当前 term 的日志，从而无法推进 commitIndex，因此整个集群便出现了活锁。该 bug 的解决方法很简单，就是让 raft 层的 leader 在 kv 层周期性的去检测下层是否包含当前 term 的日志，如果没有便 append 一条空日志，这样即可保证新选出的 leader 状态机能够迅速达到最新。其实我认为将空日志检测做到 KV 层并不够优雅，KV 层不需要去了解 raft 层有无空日志会怎么样，更优雅地方式应该是 raft 层的 leader 一上线就提交一个空日志。但总之目前在 6.824 的框架下，也只能在 KV 层做检测了。

我参考了他的做法，加入了**空日志检测机制**。原文中有提到，不再赘述。

基于以上讨论，整体架构就能进行如下设计了。

#### StartServer

注意 Shard.KVs 需要先 make() 对象。

```go
func StartServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int, gid int, ctrlers []*labrpc.ClientEnd, make_end func(string) *labrpc.ClientEnd) *ShardKV {
    labgob.Register(OperationCommand{})
    labgob.Register(ConfigCommand{})
    labgob.Register(ShardCommand{})
    labgob.Register(EmptyCommand{})

    kv := &ShardKV{
        me:              me,
        mck:             shardctrler.MakeClerk(ctrlers),
        make_end:        make_end,
        gid:             gid,
        ctrlers:         ctrlers,
        maxraftstate:    maxraftstate,
        lastapplied:     0,
        lastRequestInfo: make(map[int64]*RequestInfo),
        lastConfig:      shardctrler.Config{Num: 0},
        currentConfig:   shardctrler.Config{Num: 0},
    }
    kv.applyCh = make(chan raft.ApplyMsg)
    kv.rf = raft.Make(servers, me, persister, kv.applyCh)

    for i := range kv.Shards {
        kv.Shards[i].KVs = make(map[string]string)
    }
    kv.ApplySnapshot(-1, -1, persister.ReadSnapshot())

    go kv.Applier()
    go kv.ConfigPuller()
    go kv.ShardPuller()
    go kv.GarbageCollector()
    go kv.EmptyEntryDetector()

    return kv
}
```

#### MsgStruct

为不同操作命令定义了不同类型，这样就能通过 msg.Command.(type) 进行强转，并进一步根据 Command.Op 执行不同操作。rpc 的参数也统一采用 RPCArgs 的格式——pull Shard 请求和 GC 通知都需要 ShardId 与 ConfigNum。

```go
// cmd
type OperationCommand struct {
    Op        string
    Key       string
    Value     string
    ClerkId   int64
    RequestId int
    Ch        chan *Reply
}

type Reply struct {
    Err   Err
    Value string
}

type ShardCommand struct {
    Op              string
    Shard           *Shard
    Sid             int
    ConfigNum       int
    LastRequestInfo map[int64]RequestInfo
}

type ConfigCommand struct {
    LastConfig shardctrler.Config
    NewConfig  shardctrler.Config
}

type EmptyCommand struct {
}

// rpc
type RPCArgs struct {
    Op        string
    ShardId   int
    ConfigNum int
}

type RPCReply struct {
    Err             Err
    Shard           Shard
    ConfigNum       int
    LastRequestInfo map[int64]RequestInfo
}
```

#### Applier

和 lab3 大同小异，只是多加了一些 Command 类型的判断。

```go
func (kv *ShardKV) Applier() {
    // goroutine
    for !kv.killed() {
        for msg := range kv.applyCh {
            if msg.CommandValid {
                kv.mu.Lock()
                if msg.CommandIndex > kv.lastapplied {
                    kv.lastapplied = msg.CommandIndex
                    DPrintf("[%d %d] Get Command %+v", kv.gid, kv.me, msg.Command)

                    switch msg.Command.(type) {
                    case OperationCommand:
                        kv.ApplyCommand(msg)
                    case ConfigCommand:
                        kv.ApplyUpdateConfigCommand(msg)
                    case ShardCommand:
                        kv.ApplyShardCommand(msg)
                    case EmptyCommand:
                        kv.ApplyEmptyCommand()
                    default:
                        panic("Undefined Command Type!")
                    }

                    if kv.NeedSnapshot() {
                        kv.MakeSnapshot(msg.CommandIndex)
                    }
                }
                kv.mu.Unlock()
            } else if msg.SnapshotValid {
                kv.mu.Lock()
                kv.ApplySnapshot(msg.SnapshotIndex, msg.SnapshotTerm, msg.Snapshot)
                kv.mu.Unlock()
            }
        }
    }
}
```

#### ConfigPuller

```go
func (kv *ShardKV) ApplyUpdateConfigCommand(msg raft.ApplyMsg) {
    // locked
    Command := msg.Command.(ConfigCommand)
    lastconfig, newconfig := Command.LastConfig, Command.NewConfig
    if newconfig.Num == kv.currentConfig.Num+1 {
        kv.lastConfig = lastconfig
        kv.currentConfig = newconfig

        if newconfig.Num > 1 {
            // config 发生变化：
            // 1. 分配且仍持有的保持 Ready
            // 2. 分配但未持有的变为 NeedPull，等到拉取 shard 完成后变为 Valid
            // 3. 持有但未分配的变为 Waiting，等待其他组 pull 后被回收
            for sid, gid := range kv.lastConfig.Shards {
                if gid != kv.gid && kv.OwnShard(sid) {
                    kv.Shards[sid].ShardStatus = NeedPull
                }
                if gid == kv.gid && !kv.OwnShard(sid) {
                    kv.Shards[sid].ShardStatus = Waiting
                }
            }
        }

        DPrintf("[%d %d] Apply Config: last %+v, new %+v", kv.gid, kv.me, lastconfig, newconfig)
    }
}

func (kv *ShardKV) ConfigPuller() {
    // goroutine
    for !kv.killed() {
        if kv.rf.GetRaftState() == raft.Leader {
            kv.mu.RLock()
            CanPullConfig := true
            lastConfig, configNum := kv.currentConfig, kv.currentConfig.Num    // CurrentConfig 未来将变为 LastConfig
            for sid := range kv.currentConfig.Shards {
                if !kv.ReadyForConfigPuller(sid) {
                    CanPullConfig = false
                    break
                }
            }
            kv.mu.RUnlock()    // 及时放锁

            if CanPullConfig {
                newconfig := kv.GetNewConfig()
                if newconfig.Num > configNum {
                    if configNum == 0 && newconfig.Num > 1 { // 第一次加入集群，需初始化 lastconfig
                        lastConfig = kv.mck.Query(newconfig.Num - 1)
                    }
                    kv.rf.Start(ConfigCommand{
                        LastConfig: lastConfig,
                        NewConfig:  newconfig,
                    })
                }
            }
        }
        time.Sleep(NewConfigQueryTimeOut)
    }
}
```

#### ShardPuller & GarbageCollector

两者其实非常相似。

```go
func (kv *ShardKV) ApplyShardCommand(msg raft.ApplyMsg) {
    Command := msg.Command.(ShardCommand)
    switch Command.Op {
    case "InsertShard":
        kv.InsertShard(Command)
    case "GarbageCollect":
        kv.GarbageCollect(Command)
    default:
        panic("Undefined Command!")
    }
}

func (kv *ShardKV) InsertShard(Command ShardCommand) {
    // locked
    configNum, newshard, sid := Command.ConfigNum, Command.Shard, Command.Sid
    if configNum == kv.currentConfig.Num && kv.Shards[sid].ShardStatus == NeedPull {
        for k, v := range newshard.KVs {
            kv.Shards[sid].KVs[k] = v
        }
        for clientId, lastrequestInfo := range Command.LastRequestInfo {
            Rinfo, ok := kv.lastRequestInfo[clientId]
            if !ok || Rinfo.RequestID < lastrequestInfo.RequestID {
                kv.lastRequestInfo[clientId] = &RequestInfo{
                    lastrequestInfo.RequestID,
                    lastrequestInfo.Err,
                }
            }
        }
        kv.Shards[sid].ShardStatus = ReadyButNeedSendGC
        DPrintf("[%d %d] insert %d-th Shard %+v", kv.gid, kv.me, Command.Sid, Command.Shard)
    }
}

func (kv *ShardKV) GarbageCollect(Command ShardCommand) {
    // locked
    configNum, sid := Command.ConfigNum, Command.Sid
    if configNum == kv.currentConfig.Num {
        if kv.Shards[sid].ShardStatus == ReadyButNeedSendGC {
            kv.Shards[sid].ShardStatus = Ready
        } else if kv.Shards[sid].ShardStatus == Waiting {
            kv.Shards[sid].KVs = make(map[string]string)
            kv.Shards[sid].ShardStatus = Ready
        }
    }
}

func (kv *ShardKV) ShardPuller() {
    // goroutine
    for !kv.killed() {
        if kv.rf.GetRaftState() == raft.Leader {
            kv.mu.RLock()
            configNum := kv.currentConfig.Num // 捎带当前 config.num，防止收到过期回复
            var wg sync.WaitGroup
            for sid, gid := range kv.lastConfig.Shards {
                if kv.NeedPull(sid) { // 向前任持有者拉取 shard
                    wg.Add(1)
                    // Send RPC and Pull Shard
                    go func(sid, gid int, others []string) {
                        defer wg.Done()
                        index := 0
                        args := &RPCArgs{
                            Op:        "PullShard",
                            ShardId:   sid,
                            ConfigNum: configNum,
                        }
                        DPrintf("[%d %d] pull shard %d from %d with args %+v", kv.gid, kv.me, sid, gid, args)
                        for {
                            end := kv.make_end(others[index])
                            reply := &RPCReply{}
                            ok := end.Call("ShardKV.HandleBetweenGroupRequest", args, reply)
                            if ok && reply.Err == OK {
                                DPrintf("[%d %d] pull shard %d from %d and get KVs: %+v", kv.gid, kv.me, sid, gid, reply.Shard.KVs)
                                kv.rf.Start(ShardCommand{
                                    Op:              "InsertShard",
                                    Shard:           &reply.Shard,
                                    ConfigNum:       configNum,
                                    Sid:             sid,
                                    LastRequestInfo: reply.LastRequestInfo,
                                })
                                return
                            } // else: FailSend / ErrWrongLeader / ErrNotReady
                            index = (index + 1) % len(others)
                        }
                    }(sid, gid, kv.lastConfig.Groups[gid])
                }
            }
            kv.mu.RUnlock()
            wg.Wait()
        }
        time.Sleep(ShardPullerTimeOut)
    }
}

func (kv *ShardKV) GarbageCollector() {
    // locked
    for !kv.killed() {
        if kv.rf.GetRaftState() == raft.Leader {
            kv.mu.RLock()
            configNum := kv.currentConfig.Num // 捎带当前 config.num，防止收到过期回复
            var wg sync.WaitGroup
            for sid, gid := range kv.lastConfig.Shards {
                if kv.ReadyButNeedSendGC(sid) { // 向前任持有者发送 GC 请求
                    wg.Add(1)
                    // Send RPC and make GC
                    go func(sid, gid int, others []string) {
                        defer wg.Done()
                        index := 0
                        args := &RPCArgs{
                            Op:        "GarbageCollect",
                            ShardId:   sid,
                            ConfigNum: configNum,
                        }
                        DPrintf("[%d %d] send GC %d to %d at Config %d", kv.gid, kv.me, sid, gid, configNum)
                        for {
                            end := kv.make_end(others[index])
                            reply := &RPCReply{}
                            ok := end.Call("ShardKV.HandleBetweenGroupRequest", args, reply)
                            if ok && reply.Err == OK {
                                DPrintf("[%d %d] send GC %d to %d success", kv.gid, kv.me, sid, gid)
                                kv.rf.Start(ShardCommand{
                                    Op:              "GarbageCollect",
                                    Shard:           nil,
                                    ConfigNum:       configNum,
                                    Sid:             sid,
                                    LastRequestInfo: nil,
                                })
                                return
                            } // else: FailSend / ErrWrongLeader / ErrNotReady
                            index = (index + 1) % len(others)
                        }
                    }(sid, gid, kv.lastConfig.Groups[gid])
                }
            }
            kv.mu.RUnlock()
            wg.Wait()
        }
        time.Sleep(GarbageCollectorTimeOut)
    }
}
```

#### EmptyEntryDetector

```go
func (kv *ShardKV) ApplyEmptyCommand() {
    // DPrintf("EMPTY COMMAND")
}
func (kv *ShardKV) EmptyEntryDetector() {
    for !kv.killed() {
        if kv.rf.GetRaftState() == raft.Leader {
            if !kv.rf.HasLogAtCurrentTerm() {
                kv.rf.Start(EmptyCommand{})
            }
        }
        time.Sleep(EmptyEntryDetectorTimeOut)
    }
}
```

#### 组间 RPC

```go
func (kv *ShardKV) HandleBetweenGroupRequest(args *RPCArgs, reply *RPCReply) {
    // RPC
    if kv.rf.GetRaftState() != raft.Leader {
        reply.Err = ErrWrongLeader
        return
    }

    kv.mu.RLock()
    defer kv.mu.RUnlock()
    defer DPrintf("[%d %d] get %+v and reply %+v", kv.gid, kv.me, args, reply)

    sid, configNum := args.ShardId, args.ConfigNum
    if configNum > kv.currentConfig.Num {
        reply.ConfigNum, reply.Err = kv.currentConfig.Num, ErrNotReady
        return
    }
    // 允许接收过期 rpc，但 reply 会捎带 CurrentConfigNum，这样尽管收到过期 reply 也不会进行任何操作

    switch args.Op {
    case "PullShard":
        reply.Shard.KVs = make(map[string]string)
        for k, v := range kv.Shards[sid].KVs {
            reply.Shard.KVs[k] = v
        }

        reply.LastRequestInfo = make(map[int64]RequestInfo)
        for clerkId, lastrequestInfo := range kv.lastRequestInfo {
            reply.LastRequestInfo[clerkId] = *lastrequestInfo
        }

    case "GarbageCollect":
        kv.rf.Start(ShardCommand{
            Op:              "GarbageCollect",
            Shard:           nil,
            ConfigNum:       configNum,
            Sid:             sid,
            LastRequestInfo: nil,
        })
    }

    reply.ConfigNum, reply.Err = configNum, OK
}
```

## 总结

这么设计有以下好处：

1. pull Shard 后能立即为 client 提供服务，而无需阻塞；
2. 不同 group 之间 Shard 状态互为同步关系，网络顺畅时系统才能够持续进行；
3. 不同 ShardId 的 Shard 互相独立，当两组互相迁移 Shard 时并不会造成死锁；
4. group 能够 step-by-step 地更新 Config，所有任务都能稳定执行，而不会出现步子跨太大扯着蛋的情况；
5. 失去 Shard 所有权的 group 能够定期删除数据，而不会使存储无线增长；
6. 基于 ShardStatus 的任务执行减少了不必要的阻塞，使得整个系统设计更加优雅；

总之系统的设计还是需要灵感与无数前人的经验总结，至少 Aurora 的论文给了我很大启迪。虽然因为磕盐原因 4B 磨蹭了很久，整个 lab 前前后后磨蹭了近 3 个月，但总归是 solo && all passed 了，对 Distributed System 也有了更进一步的理解。完结撒花~
