---
title: 面经
author: Leager
mathjax: true
date: 2023-10-19 12:40:05
summary:
categories: Interview
tags:
img:
---

个人的 面试经验整理。

<!--more-->

## C++

### 左值和右值的区别？

可以取地址并具有变量名的是左值。剩下的都是右值，只存在于寄存器中，无法在内存中寻址，不具有持久性。

### 右值引用(Type&&)是什么？为什么要用右值引用？

简单来说，右值引用绑定的对象为右值，其具有变量名，所以是左值。

`func(Type&)` 可以修改形参但无法用右值传值， `func(const Type&)` 可以用右值传值但无法在函数内部对形参进行修改。可以选择在栈上开一个左值的内存然后赋予右值，再用前者，也就是 `func(Type&)` 传值，但存在开销，故提出右值引用。`func(Type&&)` 既可以传入右值，又可以修改形参。

### 拷贝构造和移动构造的区别？

前者是深拷贝，相当于在内存中创建一个副本。

后者实际是做了个浅拷贝，并在内存中改变数据所有权（把我有的给你，然后将我有的设为 nil），基于 `std::move` 和右值引用。

### std::move 和 std::forward 的区别？

可见 [Effective Modern C++ Item23](https://cntransgroup.github.io/EffectiveModernCppChinese/5.RRefMovSemPerfForw/item23.html#%E6%9D%A1%E6%AC%BE%E4%BA%8C%E5%8D%81%E4%B8%89%E7%90%86%E8%A7%A3stdmove%E5%92%8Cstdforward)

`std::move` 仅仅做了个 become 右值引用的类型转换。

`std::forward` 仅仅是将实参转为对应的引用版本，适用于万能引用下类型不明确的情况。

具体可见 [C++11 の 智能指针](../../C/C-SmartPtr)

### std::shared_ptr 和 std::unique_ptr 的异同？

这两个都是智能指针，均满足 RAII 准则，在析构时自动释放堆上分配的内存。

shared ptr 为**共享**指针，允许拷贝构造，可以由多个 shared ptr 变量同时指向同一块内存，每块内存都会维护一个引用计数器，每引用一个对象计数器加 1；每释放一个对象计数器减 1。当计数器为 0 时该内存才会被释放。

unique ptr 为**独占**指针，不允许拷贝构造，同时只能有一个 unique ptr 指向某块内存，只能通过移动语义来进行更改所有权。

### std::shared_ptr 有什么缺陷？如何解决？

shared ptr 存在循环引用的问题，可以用 `std::weak_ptr` 解决。比如下面这段代码，分别有两个 shared ptr 指向 a 和 b 所在的内存空间，outPa/inPa 与 outPb/inPb 的计数器均为 **2**。

当 `func()` 退出时，栈变量 outPa 和 outPb 结束生命周期，调用析构函数，分别使得 outPa/inPa 和 outPb/inPb 的计数值 **-1**。然而，类成员变量 inPa/inPb （的所有数据）还位于 a/b 所在的堆空间中，它们的计数器并没有归零，而是 **1**。那么永远得不到释放，这就造成了**内存泄漏**。

```C++
class B;
class A {
public:
    std::shared_ptr<B> inPb;
};

class B {
public:
    std::shared_ptr<A> inPa;
}

void func() {
    auto outPa = std::make_shared<A>(); // 视为指向堆空间 a
    auto outPb = std::make_shared<B>(); // 视为指向堆空间 b
    outPa->inPb = outPb;
    outPa->inPa = outPa;
}
```

如果使用 `std::weak_ptr<B> inPb` 来代替 `std::shared_ptr<B> inPb`，则可以解决该问题。这是因为 weak ptr 并不影响 **指向该内存的 shared ptr** 的计数器，它只作为一个**观测者**，用于监测对应的空间是否被释放（通过 `expired()` 函数），同时提供了一个 `lock()` 函数来访问地址。根据这一特性，尽管 outPa/inPa 的计数器为 2，但是 outPb 的计数器为 1，那么其在函数退出后可以对 b 的内存进行释放，从而使 inPa 的计数器 counterA-=1，而 outPa 又因为函数退出而再次使计数器 counterA-=1，进而释放 a 的内存。

此时，a/b 的内存均被释放。


### int* 和 void* 的区别？

`int*` 类型的变量会有类型信息，告诉编译器“我指向的这块内存是个 `int` 变量，如果你要读取就只能一次性读 4 字节”。其他的 `double*`、`long long*` 同理。

`void*` 意为无类型指针，可以指向任意类型的数据，但赋值给 `int*` 这种的就要配合类型转换了。直接读取是读 1 字节，毕竟也是指向了一个内存地址。

### map 和 unordered_map 的区别？

map 是**有序**表，，底层由**红黑树**实现，增删改查为 O(logn)

unordered_map 是**无序**表，底层由**哈希表**实现，增删改查为 O(1)，但当负载因子大于 0.7 时会扩容，即分配一片更大的空间，再将原来的键值对放入哈希表.

## 操作系统

### 进程和线程的区别？

进程: 资源分配的单位，拥有独立地址空间，切换时需修改页表基地址寄存器，清空 TLB 以及 CS、IP 等寄存器。新进程一开始访页时大概率会 cache miss，从而开销大。

线程: 调度的单位，同一进程下所有线程共享地址空间，但线程之间拥有独立的程序计数器与栈空间，切换时仅需修改相关寄存器，无需修改页表，故开销小。另外，不同进程之间的线程切换也会涉及到进程切换，开销变大。

本质区别在于**是否和其它单位共享页表**。

### 切换地址空间是怎样实现的？

修改页表基地址寄存器，以访问正确的页表；以及清空 TLB，防止进行错误的地址转换。当然如果 TLB 支持 ASID 就不用清空了。 

### 虚拟地址和物理地址区别？为什么要用虚拟地址？

物理地址是指实际存储在内存中的地址，它可以直接被硬件访问。物理地址是固定的，并且受到物理内存大小的限制。

虚拟地址是指软件视图中的内存地址，它是逻辑地址，不受物理内存大小的限制。通常是连续的，因此程序员可以使用连续的虚拟地址，而不必考虑实际内存中的分布情况。

如果只有物理地址，那么程序员编程时必须足够小心，以防使用了其它程序的地址，更不能访问内核空间。在页面置换时，也必须将其放到固定的位置。而引入了虚拟地址，就可以将编程与访存分离，将内存访问交给操作系统去实现（页表），进而实现进程空间隔离，保证了安全性。

具体可以参考[这篇文章](https://www.xiaolincoding.com/os/3_memory/vmem.html#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98)。

### 进程访页过程？

以**在支持二级页表的 32 位机器中取指令**为例。

首先进程根据当前 CS:IP 寄存器，进行指令地址的计算（CS<<4 + IP），从而获得相应代码段中的指令地址。注意这是一个虚拟地址，需要根据硬件转换为物理地址。

**注意**: 假设该虚拟地址的前 10 位 `PD_Index` 是页目录条目的索引，中间 10 位 `PT_Index` 是页表条目的索引，后 12 位是页内偏移 `Offset`。

先访问 TLB，TLB 实际存储的是虚拟页号 `VPN` 到物理页帧号 `PFN` 的转换。如果 TLB 命中，就直接根据 `PFN<<10 | Offset` 得到物理地址了。如果没有命中，就要获取正确的 `PFN` 并更新 TLB 条目以便未来的访问同一物理页时降低开销。

那么首先去页目录基地址寄存器中获取页目录的地址 `PD_Addr`，这是个物理地址，可以直接访问，然后根据 `PD_Addr + 4*PD_Index` （一个条目为 4 字节）获得相应页目录项条目。这一条目中存放的是相应页表的地址 `PT_Addr`，还有一些状态位（如果该页表中没有任何一个页面分配，那么有效位就是 0，反之为 1）。

这里假设页目录项有效，那么我们得到了页表，用同样的方法，我们访问地址 `PT_Addr + 4*PT_Index` 可以得到 `PFN`，假设页表项仍然有效，那就赶紧更新 TLB 然后重新访问一遍。

由于上次的插入，这次必定能获得物理地址，那么就可以愉快地访存了。

如果页目录项/页表项无效，说明我们要访问的物理页帧并没有存放我们想要的数据（页表也占据了一整个物理页帧），那么此时此刻就要去磁盘上获取数据，然后根据一定的置换规则（如 LRU）进行换页。

### 为什么要用多级页表？

32 位机器下，如果一个页面为 4KB 并且采用单级页表，那就要整整 4MB 的连续空间，而且不一定这 2^20 个页面都得到分配，会有很大一部分页表项是浪费的。

二级页表就不会有这种情况。假设前 10 位为页目录索引，中间 10 位为页表索引，如果某个页表所指向的 2^10 个页面都没得到分配，那么就不会为这个页表分配物理页帧，页目录中会将该页表的有效位设为 0。这样就大大节省了空间，还防止了无法分配过大连续内存的问题。

### 用户态和内核态的区别？怎么切换？为什么要区分这两个级别？

用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有最高的特权级。运行在用户态的程序不能直接访问内核，例如不能使用系统调用。Due to the complexity of developing and maintaining the kernel, only the most essential and performance-critical code are placed in the kernel. Other things, such as GUI, management and control code, typically are programmed as user-space applications. This practice of splitting the implementation of certain features between kernel and user space is quite common in Linux.（引用自 [Linux Journal](https://www.linuxjournal.com/article/7356)）

处于用户态的进程可以通过 1.请求系统调用 2.硬件中断 3.软件异常 等方式陷入内核态，然后再利用 ret 指令返回用户态。

如果只有用户态，那就完全没法利用操作系统的内核功能；如果只有内核态，那所有进程都可以访问内核数据，甚至修改内核，不安全。

### 进程有几个栈？

两个。用户态一个，内核态一个。两个栈的数据不互通，也是为了安全性考虑。

### 执行系统调用的过程？

1. 将系统调用号放到寄存器 EAX 中，执行 `int 0x80` 指令发出中断；
2. CPU 收到中断后，根据中断号 `0x80` 到中断向量表中查找对应中断描述符，其中包含中断服务程序 `system_call` 的代码段选择子；
3. 根据该段选择子去全局描述符表 GDT 里取得段描述符，段描述符 `SD` 里保存了中断服务程序的段基址和属性信息，此时 CPU 就得到了中断服务程序的起始地址。这里，CPU 会检查 CS.CPL 和 SD.DPL，以确保中断服务程序的特权级是高于当前用户程序的，或者说当前程序有权限使用中断服务程序，这可以避免用户应用程序访问特殊的中断门；
4. 在执行 `system_call` 前，CPU 会先从当前进程的 TSS 字段里取得内核栈地址，然后保存用户进程现场（CS、IP、SS、ESP 等信息），并将新的内核栈信息赋给 SS 和 ESP；
5. 开始执行 `system_call`，根据 EAX 寄存器存储的系统调用号，从系统调用表上找到相应的系统调用并调用；
6. 执行 `itret` 指令返回用户态，取出内核栈中保存的用户进程信息，重新赋值给相关寄存器，至此系统调用完成；

### 堆和栈的区别？

堆和栈是内存模型中的两片不同区域。

堆存放程序员动态分配的数据，同时需要程序员手动释放，由低向高增长，空间较大。

栈存放一般函数局部变量，一个函数调用对应一个栈帧，由操作系统自动管理栈空间的分配与释放，由高向低增长，空间较小，需要预防栈溢出的异常。

### 调用 malloc 分配一个 100B 大小的空间，内存会发生怎样的变化？

事实上内存并不会发生变化。

如果只调用了 `malloc()`，那么只会在该进程的虚拟地址空间中划分出 100B，新增一个页表项，设置 flag=0，表明未分配物理地址。

等到实际访问这个虚拟地址时，会发现对应的物理地址并不存在，触发缺页中断，这个时候才会在堆上进行实际的内存分配(brk)，并再次修改那个页表项。后续的访问就能正常进行。

## 计算机网络

### 说一下五层网络模型，并且指出 TCP 处于哪一层？

应用层，传输层，网络层，数据链路层，物理层。TCP 位于传输层。

### TCP 和 UDP 的区别？

TCP: 数据传输前要用三次握手建立连接，数据传输过程中提供流量控制（TCP 拥塞控制）和有序性（序列号和确认号），因而效率不高，但非常可靠；

UDP: 无需连接，不计后果地发送，即便丢包也无所谓，虽然不可靠，但效率很高，一般用于视频、DNS 查询等；

### 为什么视频可以用 UDP？

因为即使丢包也可以用插值算法补帧，允许这种不可靠，同时更要追求视频的实时性。

### 点击 url 到显示网页之间发生了什么？

见另一篇文章 [点击 Url 到显示网页之间发生了什么？](../../Computer-Network/WhatHappenedAfterClickUrl)

### TCP 和 UDP 都是怎么处理数据量较大的包的（如 5KB）？

因为以太网 MTU=1500MB 的缘故，IP 层会将过大的包进行分片，处理方式为在头部设置**标识位**与**片偏移**。TCP 和 UDP 都不负责分片工作，而是将其交付给下一层去做。

特别的，IP 首部的长度字段为 16 位，意味着同一个分片组最大可以容纳 64KB 的 TCP/UDP 数据，那对 TCP/UDP 而言 5KB 简直是小意思，不会分片。而如果超过 64 KB，那就要分成多个 TCP/UDP 包发送了。

### 如果应用层基于 TCP 发送了两个分别为 100B 和 200B 大小的数据包，接收方可能的情况有哪些？换成 UDP 呢？

理想情况下，接收方会先收到 100B 的包（记为 **「包1」**），再收到 200B 的包（记为 **「包2」**）。

非理想情况下：

1. 数据包可能是乱序到达的，硬件层面可能会先收到「包2」，一层层往上交付后，TCP 模块会发现这个包的序列号与期望值不匹配，将其数据缓存，等到后续收到后「包1」，解包后再和之前缓存的「包2」数据一并交给上层；
2. 由于 TCP 基于字节流，在传输层无法确认消息边界，总是在字节流冲满 buffer 后再被上层一次性取走，所以上层拿到的数据并不一定是完整的「包1」或者「包2」，这就是出现了粘包；

如果使用 UDP：

1. 对于乱序到达的情况，则先到的「包2」会直接被交付，而不用等「包1」有没有到，因为 UDP 本身是不提供可靠传输的，不用保证数据的有序性；
2. 对于粘包情况，UDP Header 指明了数据长度，一个 UDP 包就是一个用户消息，所以即便「包1」和「包2」同时到达，UDP 也能正确分清数据的边界，不会产生粘包现象；

### select/poll/epoll 的区别

太经典了，[直接看这篇足矣](https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#_9-2-i-o-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-select-poll-epoll)。

### 网络层如何转发数据包？路由器是如何进行自学习的？

交换机根据源 MAC 地址建立转发表，根据目的 MAC 地址转发，如果目的 MAC 地址不在，就发一个 ARP 广播请求来获取。

路由器根据目的 IP 地址进行将数据包由特定端口发出。对于静态路由而言，转发表需管理员手动配置；而动态路由则会根据路由协议（如 RIP）定时与其他路由器交换路由信息，从而建立转发表。

## 数据库系统

### 说下 ACID 分别代表什么意思？

A: Atomic 原子性

C: Consistency 一致性

I: Isolation 隔离性

D: Durability 持久性

### 事务隔离级别分别有哪些？

读未提交: 这种隔离级别不加任何锁，有可能读事务 reader 读取到了写事务 writer 写入数据库但未提交的数据。这就是**脏读**。

读提交: 这种隔离级别上了写锁，但同一事务 reader 对同一个键的前后两次读取之间可能会因为穿插了另一事务 writer 的写入，从而读取到了不一样的数据。这就是**不可重复读**。

可重复读：这种隔离级别下，对某个键的读取开始后不再允许任何写入，因而不会出现上述情况，前后两次读结果必定相同。但在某些场景比如 `select * from table; insert values {k1, v1} into table;` 中，两个语句之间由于另一事务也插入了 `{k1, v1}` 这一键值对，导致 `insert` 失败，原因是键冲突，但 `select` 时并没有看到这一条数据。这就是**幻读**。

可序列化: 这种隔离级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。

## 项目

### 为什么 15445 里选择用 Extendible Hash Table 而不是 STL 里的 hash map/unordered map？

STL 中的 hash map/unordered map 底层基于**哈希表**，采用**开链法**处理冲突。当负载因子（元素数量/桶数量）超过一定阈值时，会进行**扩容**：分配一片更大的哈希表空间，并且将原有的**所有**元素拿出来 hash 到新的表中。这一扩容策略开销很大。

而 EHT 巧妙地解决了扩容问题。虽然它也是采用**开链法**处理冲突，但只有当目标 bucket 的元素数量将超出 `2^local depth` 时才会触发桶扩容，无非是将桶的 `local depth` 增加，分配新桶并且将原来的 `2^local depth` 个元素加上新插入的那个元素进行 hash 即可，不需要对所有元素进行如此处理，开销大大降低了。

即便是 `local depth = global depth` 时的表扩容，也仅仅是拷贝原有的桶地址，不改变其他桶的内容（有点像进程 fork 时的 COW 策略），只将待 split 的桶进行元素的 rehash，这样一来其扩容的开销仅仅是“拷贝桶地址+分配新桶+原桶数据 rehash”，和桶扩容比起来也就是多了一个拷贝 `2^global depth` 个地址的开销，算不了什么。而且桶扩容的时机取决于 `local depth`，随着逐步进行表扩容，一个桶内可以容纳越来越多的元素，虽然后面进行一次桶扩容会对更多元素进行处理，但均摊下来成本还是低的（有点像 `vector` 的扩容机制）。

所以，在扩容开销方面，EHT 优势尽显。

而增删查方面，两者可以说是五五开，毕竟都是先经过 hash function 到某一桶，然后再遍历整个桶。

## 算法题

### 链表

1. 参考 std::list 实现一个模板类，需要支持：拷贝赋值移动构造、头尾增删、size()、clear()、reverse()。**进阶**：将 reverse() 优化为 O(1)。

```C++
template<class T>
class List {
    public:
        List() : head(nullptr), tail(nullptr), listSize(0) {}
        List(const List<T>& other) {
            // 对 other 的每一个 node 进行深拷贝
            listSize = other.listSize;
        }
        List<T>& operator=(const List<T>& other) {
            // 同拷贝构造
            return *this;
        }
        List(List<T>&& other) {
            head = other.head
            tail = other.tail;
            other.head = other.tail = nullptr;
            listSize = other.listSize;
        }
        List<T>& operator=(List<T>&& other) {
            // 同移动构造
            return *this;
        }

        T pop_back() {
            T result;
            // corner case: size=0, 需抛出异常
            // else: tail 移到 tail->prev, 释放 tail->next, tail->next = nullptr
            listSize--;
            return result;
        }
        T pop_front() {
            // 思路同 pop_back()
        }
        void push_back(const T& data) {
            // corner case: size=0, 需令 head = tail = new node(data)
            // else: tail->next = new node(data), tail->next->prev = tail, tail = tail->next;
            listSize++;
        }
        void push_front(const T& data) {
            // 思路同 push_back
        }

        size_t size() const { return listSize; }
        void clear() {
            while (head->next) {
                head = head->next;
                delete head->prev;
            }
            delete head;
            head = tail = nullptr;
            listSize = 0;
        }

        void reverse() {
            // 如果不优化, 就是交换 head 和 tail, 然后遍历链表修改 prev 和 next, 需要 O(n)
            // 优化后, 同样需交换 head 和 tail，此时可以设置一个 flag 表示顺序还是逆序
            //     顺序：按 next 遍历链表
            //     逆序：按 prev 遍历链表
        }

    private:
        struct node {
            node(const T& newData) : data(newData), prev(nullptr), next(nullptr) {}
            T data;
            node* prev;
            node* next;
        };

        bool flag = true; // used for O(1) reverse()
        node* head;
        node* tail;
        size_t listSize;
};
```

### 数组

1. 有一个长为 n 的数组 `int nums[n]`，且数组内任意元素均满足 `1 <= nums[i] <= n`。数组中有些元素出现了两次，其余只出现了一次，打印那些出现了两次的元素。

```C++
// 不断将 nums[i] 与 nums[nums[i]-1] 进行交换，直至下标为 nums[i]-1 的位置上已经有了正确的元素(即 nums[i])
// 如果都只出现了一次，那么这种方式会使得最终的数组有序 {1, 2, ..., n}，且时间复杂度为 O(n)
// 一旦有元素出现了两次，那么必然会在遍历的过程中，发现自己应该位于的位置被"另一个自己"占据了，说明出现了两次，加入结果集返回
void solution(const vector<int>& nums) {
    unordered_set<int> result;
    int n = nums.size();
    for (int i = 0; i < n; i++) {
        while (nums[i] != nums[nums[i]-1]) {
            swap(nums[i], nums[nums[i]-1]);
        }
        if (i != nums[i]-1 && nums[i] == nums[nums[i]-1]) {
            if (result.count(nums[i])) {
                cout << nums[i] << '\n';
            } else {
                result.insert(nums[i]);
            }
        }
    }
}
```